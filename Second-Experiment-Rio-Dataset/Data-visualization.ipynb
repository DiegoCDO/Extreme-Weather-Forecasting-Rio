{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24d04db",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b177a",
   "metadata": {},
   "source": [
    "This Jupyter notebook allowed me to choose the station I wanted to use for my experiments. Please note that I highly recommand you to restart your kernel when you enter a new main section (that began with a cell containing imports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf98a9",
   "metadata": {},
   "source": [
    "## All stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6638952f",
   "metadata": {},
   "source": [
    "This jupyter notebook only consider the station that are both metrological AND rainfall station.\n",
    "\n",
    "In this notebook some data visualization is made on the dataset to see there viability for my next experiment (Second experiment directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a16f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from time import time\n",
    "from threading import Thread\n",
    "from threading import Lock\n",
    "\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f30d61",
   "metadata": {},
   "source": [
    "The **data extraction Jupyter notebook** need to be run **before** this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac9f2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if \"data/output\" not in os.getcwd():\n",
    "    os.chdir(\"data/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf4f71",
   "metadata": {},
   "source": [
    "Get the list of the meteorological station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c318f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = !ls AlertaRio_DadosMet/full | sed \"s/\\.csv//g\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f5755",
   "metadata": {},
   "source": [
    "Get the list of the rainfall station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_station_list = !ls AlertaRio_DadosPluv/full | sed \"s/\\.csv//g\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12ab1c0",
   "metadata": {},
   "source": [
    "### Rainfall and meteorological station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1893f8e",
   "metadata": {},
   "source": [
    "Checking which stations are both meteorological and rainfall station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e1484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for station in station_list:\n",
    "    if station in rainfall_station_list:\n",
    "        print(\"OK:\", station)\n",
    "    else:\n",
    "        print(\"Not Ok:\", station)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81247d08",
   "metadata": {},
   "source": [
    "The following station are both meteorological and rainfall station :\n",
    "\n",
    "- alto_da_boa_vista\n",
    "- guaratiba\n",
    "- iraja\n",
    "- jardim_botanico\n",
    "- riocentro\n",
    "- santa_cruz\n",
    "- sao_cristovao\n",
    "- vidigal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b6974",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b9a9f",
   "metadata": {},
   "source": [
    "Loading the data of all the stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf46e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "sources = ['AlertaRio_DadosPluv', 'AlertaRio_DadosMet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d65a1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for station in station_list:\n",
    "    data[station] = {}\n",
    "    for source in sources:\n",
    "        print(source + \"/full/\" + station + \".csv\")\n",
    "        data[station][source] = pd.read_csv(source + \"/full/\" + station + \".csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68425175",
   "metadata": {},
   "source": [
    "### Checking the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59667b80",
   "metadata": {},
   "source": [
    "Convert the date to pandas datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84ec6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_time = time()\n",
    "for station in station_list:\n",
    "    for source in sources:\n",
    "        data[station][source]['datetime'] = pd.to_datetime(data[station][source]['Dia'] + data[station][source]['Hora'], format='%d/%m/%Y%H:%M:%S')\n",
    "        data[station][source].set_index('datetime', inplace=True)\n",
    "print(time() - init_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bb3cd",
   "metadata": {},
   "source": [
    "Checking the date (if the right format has been read DD/MM/YYYY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798fb7a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[station][source].head(1500).tail() # Dates seems ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df465d1",
   "metadata": {},
   "source": [
    "Check for dupplicated values (if there was dupplicated values, it would mean the script didn't worked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9a6ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for station in station_list:\n",
    "    for source in sources:\n",
    "        print(station, source)\n",
    "        print(len(data[station][source]), len(data[station][source][data[station][source].index.duplicated() == True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4931133",
   "metadata": {},
   "source": [
    "Check if the data is sorted by dates (if it wasn't, it would mean the script didn't worked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc670478",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "is_sorted = True\n",
    "\n",
    "for station in station_list:\n",
    "    for source in sources:\n",
    "        is_sorted &= data[station][source].index.is_monotonic_increasing\n",
    "        is_sorted &= data[station][source].sort_index().equals(data[station][source])\n",
    "print(is_sorted)\n",
    "# The data is sorted by index (Checking the amount of missing data in each station.dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d66ea",
   "metadata": {},
   "source": [
    "Checking the type of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0891521",
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in station_list:\n",
    "    print(\"=====\", station, \"=====\")\n",
    "    for source in sources:\n",
    "        print(\"\\t\", source)\n",
    "        print(data[station][source].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e557b",
   "metadata": {},
   "source": [
    "All the features have the right format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63aef2",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "Checking the amount of missing data in each station."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2d5fe3",
   "metadata": {},
   "source": [
    "All the missing data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c81cc75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(station_list), len(sources), figsize=(17, 10 * len(station_list)))\n",
    "\n",
    "for a, station in zip(ax[:,0], station_list):\n",
    "    a.set_ylabel(station, rotation=0, size='large')\n",
    "    \n",
    "for a, source in zip(ax[0], sources):\n",
    "    a.set_title(source)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(station_list)):\n",
    "    for j in range(len(sources)):\n",
    "        station = station_list[i]\n",
    "        source = sources[j]\n",
    "        \n",
    "        N = data[station][source].shape[0] * data[station][source].shape[1]\n",
    "        N_missing = data[station][source].isnull().sum().sum()\n",
    "        ax[i][j].pie([N - N_missing, N_missing], autopct='%1.2f%%')\n",
    "        ax[i][j].legend([\"Data\", \"Missing data\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53634f82",
   "metadata": {},
   "source": [
    "Converting all the data to have a 15 minutes frequency. (In pandas minute is T because M is for month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b407a64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_complete = {}\n",
    "\n",
    "for station in station_list:\n",
    "    data_complete[station] = {}\n",
    "    for source in sources:\n",
    "        data_complete[station][source] = data[station][source].asfreq(\"15T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b0866f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(station_list), len(sources), figsize=(17, 10 * len(station_list)))\n",
    "\n",
    "for a, station in zip(ax[:,0], station_list):\n",
    "    a.set_ylabel(station, rotation=0, size='large')\n",
    "    \n",
    "for a, source in zip(ax[0], sources):\n",
    "    a.set_title(source)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(station_list)):\n",
    "    for j in range(len(sources)):\n",
    "        station = station_list[i]\n",
    "        source = sources[j]\n",
    "        \n",
    "        N = data_complete[station][source].shape[0] * data_complete[station][source].shape[1]\n",
    "        N_missing = data_complete[station][source].isnull().sum().sum()\n",
    "        ax[i][j].pie([N - N_missing, N_missing], autopct='%1.2f%%')\n",
    "        ax[i][j].legend([\"Data\", \"Missing data\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a299aa",
   "metadata": {},
   "source": [
    "As we can see there is a lot of missing data, this can be explain easy. Indeed some station changed there sampling rate during there usage, so as São Cristóvão has a pretty low amount of missing data and don't have this frequency problem, I will use São Cristóvão dataset for my experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6837c488",
   "metadata": {},
   "source": [
    "## São Cristóvão dataset\n",
    "\n",
    "In this section some information are gathered from the dataset such as amount of missing data, features, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from time import time\n",
    "from threading import Thread\n",
    "from threading import Lock\n",
    "\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6a2fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if \"data/output\" not in os.getcwd():\n",
    "    os.chdir(\"data/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd295458",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_dict = {\n",
    "    \"15min\" : \"15min\",\n",
    "    \"01h\" : \"01h\",\n",
    "    \"04h\" : \"04h\",\n",
    "    \"24h\" : \"24h\",\n",
    "    \"96h\" : \"96h\",\n",
    "    \"DirVento\" : \"WindDir\",\n",
    "    \"Pressao\" : \"Pressure\",\n",
    "    \"Temperatura\" : \"Temperature\",\n",
    "    \"Umidade\" : \"Humidity\",\n",
    "    \"VelVento\" : \"WindSpeed\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8090d",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0309592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "station = \"sao_cristovao\"\n",
    "sources = ['AlertaRio_DadosPluv', 'AlertaRio_DadosMet']\n",
    "data[station] = {}\n",
    "source = sources[0]\n",
    "data[station][source] = data[station][source] = pd.read_csv(source + \"/full/\" + station + \".csv\", sep=',')\n",
    "source = sources[1]\n",
    "data[station][source] = data[station][source] = pd.read_csv(source + \"/full/\" + station + \".csv\", sep=',')\n",
    "\n",
    "for source in sources:\n",
    "    data[station][source]['datetime'] = pd.to_datetime(data[station][source]['Dia'] + data[station][source]['Hora'], format='%d/%m/%Y%H:%M:%S')\n",
    "    data[station][source].set_index('datetime', inplace=True)\n",
    "    data[station][source] = data[station][source].asfreq(\"15T\")[\"2000\":\"2023-05-18 02:00:00\"]\n",
    "data[station][sources[1]].drop(columns=[\"Chuva\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c30ab",
   "metadata": {},
   "source": [
    "### Checking some data content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f863acb",
   "metadata": {},
   "source": [
    "During the first 2 years, the station doesn't contains data on wind, temperature and humidity, therefore, the data will be used after 2002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb9ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[station][sources[1]].loc['2000'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f662b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[station][sources[1]].loc['2000'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036f607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[station][sources[1]].loc['2001 11'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca3fb3",
   "metadata": {},
   "source": [
    "### Plotting Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d8f48d",
   "metadata": {},
   "source": [
    "Amount of missing data in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(sources), figsize=(17, 10))\n",
    "\n",
    "year = '1800'\n",
    "\n",
    "station = \"sao_cristovao\"\n",
    "for source in sources:\n",
    "    i = sources.index(source)\n",
    "    N = data[station][source][year:].shape[0] * data[station][source][year:].shape[1]\n",
    "    N_missing = data[station][source][year:].isnull().sum().sum()\n",
    "    ax[i].pie([N - N_missing, N_missing], autopct='%1.2f%%')\n",
    "    ax[i].legend([\"Data\", \"Missing data\"])\n",
    "    ax[i].set_title(source)\n",
    "plt.title(\"Missing data in General of the São Cristóvão station\")\n",
    "    \n",
    "# plt.tight_layout()\n",
    "plt.savefig(\"Fig/Dataset-full.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81970a79",
   "metadata": {},
   "source": [
    "Amount of missing data from 2002 to today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a4268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(sources), figsize=(18, 10))\n",
    "\n",
    "year = '2002'\n",
    "\n",
    "station = \"sao_cristovao\"\n",
    "for source in sources:\n",
    "    i = sources.index(source)\n",
    "    N = data[station][source][year:].shape[0] * data[station][source][year:].shape[1]\n",
    "    N_missing = data[station][source][year:].isnull().sum().sum()\n",
    "    ax[i].pie([N - N_missing, N_missing], autopct='%1.2f%%')\n",
    "    ax[i].legend([\"Data\", \"Missing data\"])\n",
    "    ax[i].set_title(source)\n",
    "plt.title(\"Missing data from 2002 of the São Cristóvão station\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.savefig(\"Fig/Dataset-2002.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8619b",
   "metadata": {},
   "source": [
    "### Creating one dataframe\n",
    "\n",
    "Combining the 2 dataset into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e099f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['Dia', 'Hora']\n",
    "data_features = pd.concat([data[\"sao_cristovao\"][\"AlertaRio_DadosPluv\"].drop(columns=drop_list), data[\"sao_cristovao\"][\"AlertaRio_DadosMet\"].drop(columns=drop_list)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c6a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features.loc['2002'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
