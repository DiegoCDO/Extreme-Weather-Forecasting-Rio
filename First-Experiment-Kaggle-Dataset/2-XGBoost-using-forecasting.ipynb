{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3db4f47",
   "metadata": {},
   "source": [
    "# Prediction with skforecaster\n",
    "\n",
    "In this Jupyter notebook, another approach is used to predict the future and improve the results. This notebook use the skforecaster python module combined with XGBoost regressor. The skforecaster python module allow the user to realize simple prediction using time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34012f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c053da8",
   "metadata": {},
   "source": [
    "## Renaming the column and convert the date to pandas format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa69055",
   "metadata": {},
   "source": [
    "In this section the data is loaded and sorted by dates and convert to the pandas datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dec332",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(\"PJME_hourly.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a89c8bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_data[\"Datetime\"] = pd.to_datetime(original_data[\"Datetime\"])\n",
    "original_data.rename({\"Datetime\" : \"date\", \"PJME_MW\" : \"out\"}, axis=1, inplace=True)\n",
    "original_data.sort_values(\"date\", ascending=True, inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d51576",
   "metadata": {},
   "source": [
    "Removing the duplicated data by keeping only the first one. Why keeping the first one? Because it is fast, easy and unlikely to highly impact our training are there is only a few duplicated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29770af",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.set_index('date', inplace=True)\n",
    "pd.concat([original_data[original_data.index.duplicated(keep=\"first\") == True],\n",
    "          original_data[original_data.index.duplicated(keep=\"last\") == True]])\n",
    "original_data = original_data[~original_data.index.duplicated(keep='first')]\n",
    "original_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e212889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = original_data.copy()\n",
    "\n",
    "data_features.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b72183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    out = df.copy()\n",
    "    out[\"hour\"] = out.index.hour\n",
    "    out[\"day\"] = out.index.day\n",
    "    out[\"month\"] = out.index.month\n",
    "    out[\"year\"] = out.index.year\n",
    "    \n",
    "    out['quarter'] = out.index.quarter\n",
    "    out['dayofyear'] = out.index.dayofyear\n",
    "    out['dayofmonth'] = out.index.day\n",
    "    \n",
    "    out['weekofyear'] = out.index.isocalendar().week.astype(np.int64)\n",
    "    \n",
    "    return out\n",
    "\n",
    "data_features = get_features(data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005913aa",
   "metadata": {},
   "source": [
    "## First approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0684f20",
   "metadata": {},
   "source": [
    "### Choosing frequency for skforecaster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349d9b5a",
   "metadata": {},
   "source": [
    "Skforecaster need a constant frequency to work properly. As the dataset have some missing data we can't directly use a frequency of 1h as we should, therefore, here a frequency of 3h is used (2h also don't work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ffc590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data_features.asfreq('3h')\n",
    "na = data.isna()\n",
    "na[na['out'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f3064",
   "metadata": {},
   "source": [
    "### Partitionning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb386346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_feats, test_feats = train_test_split(data.sort_values('date'), shuffle=False)\n",
    "train_feats.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e982831",
   "metadata": {},
   "source": [
    "### Training the skforecaster model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435534eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"n_estimators\" : 600,\n",
    "    \"base_score\" : 0.5,\n",
    "    \"max_depth\" : 6,\n",
    "    \"learning_rate\" : 0.01\n",
    "}\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "                    regressor = xgb.XGBRegressor(tree_method=\"gpu_hist\",\n",
    "                       **args),\n",
    "                    lags = 200\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=train_feats['out'])\n",
    "# forecaster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fffc7e9",
   "metadata": {},
   "source": [
    "### Evaluating the forecasting model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd1db9",
   "metadata": {},
   "source": [
    "Performance visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b1d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = forecaster.predict(steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d3c52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.set_title('Testing Data/predicted value')\n",
    "ax.plot(preds.index, preds, alpha=0.7, color=\"blue\")\n",
    "test_feats.loc[preds.index]['out'].plot(ax=ax, alpha=0.7, color=\"red\")\n",
    "ax.legend(['Prediction', 'Testing Set'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdddebc",
   "metadata": {},
   "source": [
    "## Try to handle the missing data with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53aa61c",
   "metadata": {},
   "source": [
    "Try to manage the missing data with XGBoost then a frequency of 1h is obtained in the dataset and can be used to train a skforecaster model with a better frequency and hopefully better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102fe8fe",
   "metadata": {},
   "source": [
    "### Creating columns to add previous points features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colums_names(column_names, N):\n",
    "    column_names = list(column_names)\n",
    "    names = []\n",
    "    for i in range(N, 0, -1):\n",
    "        for name in column_names:\n",
    "            names.append(name + str(i))\n",
    "    names.extend(column_names)\n",
    "    return names\n",
    "\n",
    "data_features.reset_index(inplace=True)\n",
    "all_available_features = list(data_features.columns)\n",
    "\n",
    "N = 2 # Number of points to predict future\n",
    "data_multiple = data_features.copy()\n",
    "\n",
    "for i in range(1, N):\n",
    "    data_multiple = pd.concat([data_multiple.iloc[:-1].reset_index(drop=True), data_features.iloc[i:].reset_index(drop=True)], axis=1)\n",
    "\n",
    "data_multiple = pd.concat([data_multiple.iloc[:-1].reset_index(drop=True), data_features.iloc[N:].reset_index(drop=True)], axis=1)\n",
    "\n",
    "data_multiple.columns = get_colums_names(all_available_features, N)\n",
    "data_multiple.set_index(\"date\", inplace=True)\n",
    "\n",
    "data_features.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7343ba",
   "metadata": {},
   "source": [
    "Defining the training features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = data_multiple.columns\n",
    "\n",
    "training_features_list = ['hour', 'day', 'month', 'year', 'quarter', 'dayofyear',\n",
    "       'dayofmonth', 'weekofyear', 'out']\n",
    "\n",
    "training_features_list = ['hour', 'month', 'out']\n",
    "\n",
    "def is_training_feature(feature, training_features):\n",
    "    for training_feature in training_features:\n",
    "        if feature != \"out\" and \\\n",
    "        training_feature == feature[:len(training_feature)] and \\\n",
    "        (feature[len(training_feature):].isnumeric() or feature[len(training_feature):] == \"\"):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "training_features = list(filter(lambda x : is_training_feature(x, training_features_list), all_features))\n",
    "\n",
    "target = \"out\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb4ad0",
   "metadata": {},
   "source": [
    "Partitionning with the last desired features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c262a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data_multiple, shuffle=False)\n",
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ca08f",
   "metadata": {},
   "source": [
    "Training the model XGBoost model to fill the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54621bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "args = {\n",
    "    \"n_estimators\" : 1200,\n",
    "    \"base_score\" : 0.5,\n",
    "    \"max_depth\" : 6,\n",
    "    \"learning_rate\" : 0.01\n",
    "}\n",
    "\n",
    "reg = xgb.XGBRegressor(tree_method=\"gpu_hist\",\n",
    "                       **args)\n",
    "\n",
    "t = time()\n",
    "reg.fit(train[training_features], train[target],\n",
    "        eval_set=[(train[training_features], train[target]), (test[training_features],test[target])],\n",
    "        verbose=100)\n",
    "print(time() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fb680",
   "metadata": {},
   "source": [
    "Performance evaluation using the RMSE metric of XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d0ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = reg.predict(train[training_features])\n",
    "preds_test = reg.predict(test[training_features])\n",
    "\n",
    "print(\"Training score:\", reg.score(train[training_features], train[target]))\n",
    "print(\"Testing score:\", reg.score(test[training_features], test[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe1e56",
   "metadata": {},
   "source": [
    "Performance visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c106ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = '2018 05'\n",
    "\n",
    "preds_period = reg.predict(test.loc[period][training_features])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.set_title('Testing Data/predicted value')\n",
    "ax.plot(test.loc[period].index, preds_period, alpha=0.7, color=\"blue\")\n",
    "test.loc[period]['out'].plot(ax=ax, alpha=0.7, color=\"red\")\n",
    "ax.legend(['Prediction', 'Testing Set'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2cfe71",
   "metadata": {},
   "source": [
    "### Fill the missingdata using the trained model\n",
    "\n",
    "As the model is trained to use the N previous points to guess the next one, it can now be used to fill the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cebc3e7",
   "metadata": {},
   "source": [
    "Making sure there is no duplicated dates :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5706752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_multiple[data_multiple.duplicated() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ecb01",
   "metadata": {},
   "source": [
    "Creating the index with all the dates that should be in the dataset if there wasn't missing data. In this dataset the missing data is not written as NaN, the date is simply not in the dataset. Therefore a range of date with also the date that are supposed to be in the dataset is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a35368",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = data_multiple.iloc[0].name\n",
    "end_date = data_multiple.iloc[-1].name\n",
    "\n",
    "dateRange = pd.date_range(start_date, end_date, freq='1h')\n",
    "# dateRange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0556f8da",
   "metadata": {},
   "source": [
    "Initialization of the new DataFrame, that will contains the filled values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_df = pd.DataFrame(index=dateRange)\n",
    "filled_df['out'] = 0\n",
    "# filled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435248a9",
   "metadata": {},
   "source": [
    "Filling the missing data (the code isn't effective and could be improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5fdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "mapping_dict = {}\n",
    "for feature in all_available_features:\n",
    "    for i in range(N, 0, -1):\n",
    "        if (feature != \"date\") or i != 1:\n",
    "            mapping_dict[feature + str(i)] = feature + str(i-1) if i > 1 else feature\n",
    "    \n",
    "# mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d2ee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = pd.Timedelta(\"1h\")\n",
    "\n",
    "last = None\n",
    "for dt in filled_df.index:\n",
    "    try:\n",
    "        filled_df.loc[dt]['out'] = data_features.loc[dt]['out']\n",
    "        last = dt\n",
    "    except:\n",
    "        last_row = data_multiple.loc[dt - pd.Timedelta(\"1h\"):dt - pd.Timedelta(\"1h\")].copy()\n",
    "        pred_row = last_row.copy()\n",
    "        for k in mapping_dict:\n",
    "            pred_row[k] = last_row[mapping_dict[k]]\n",
    "        pred_row['date'] = dt\n",
    "        filled_df.loc[dt, 'out'] = reg.predict(pred_row[training_features])[0]\n",
    "\n",
    "filled_df.loc[filled_df['out'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2723548",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98da1ff",
   "metadata": {},
   "source": [
    "Making sure the data has a frequency of 1h and partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17c6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_feats, test_feats = train_test_split(filled_df, shuffle=False, train_size=np.random.random())\n",
    "train_feats = train_feats.asfreq('1h')\n",
    "test_feats = test_feats.asfreq('1h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b58d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"n_estimators\" : 800,\n",
    "    \"base_score\" : 0.5,\n",
    "    \"max_depth\" : 6,\n",
    "    \"learning_rate\" : 0.01\n",
    "}\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "                    regressor = xgb.XGBRegressor(tree_method=\"gpu_hist\",\n",
    "                       **args),\n",
    "                    lags = 200\n",
    "             )\n",
    "\n",
    "\n",
    "forecaster.fit(y=train_feats['out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf25f7",
   "metadata": {},
   "source": [
    "### Predicting the future and evaluating the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = forecaster.predict(steps=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e662a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.set_title('Testing Data/predicted value')\n",
    "ax.plot(test_feats.loc[preds.index]['out'], alpha=1, color=\"blue\")\n",
    "ax.plot(preds.index, preds, alpha=0.7, color=\"red\")\n",
    "ax.legend(['Testing Set', 'Prediction'])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
