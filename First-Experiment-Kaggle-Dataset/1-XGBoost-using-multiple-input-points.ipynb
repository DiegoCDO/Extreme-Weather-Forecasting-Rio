{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fdfd9b6",
   "metadata": {},
   "source": [
    "# XGBoost using multiple input points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1955a3",
   "metadata": {},
   "source": [
    "The objective of this notebook is to apply XGBoost algorithm on a simple dataset to predict the future. As the dataset contains the energy consumption for each timestamp, the final goal is to apply a regression XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f89453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903c6522",
   "metadata": {},
   "source": [
    "Reading the dataset with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58768d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"PJME_hourly.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe7eed8",
   "metadata": {},
   "source": [
    "## Renaming the column and convert the date to pandas format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb17a00",
   "metadata": {},
   "source": [
    "Convert the date into pandas date and sort by date to allow further computation (such as partitionning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ffdcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data.dtypes)\n",
    "data[\"Datetime\"] = pd.to_datetime(data[\"Datetime\"])\n",
    "data.rename({\"Datetime\" : \"date\", \"PJME_MW\" : \"out\"}, axis=1, inplace=True)\n",
    "data.sort_values(\"date\", ascending=True, inplace=True, ignore_index=True)\n",
    "print(data.head())\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1167beb2",
   "metadata": {},
   "source": [
    "## Extracting all the features to improve our evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85e8c2",
   "metadata": {},
   "source": [
    "XGBoost can't use the date of pandas, XGBoost only work with numbers (float, int, etc). Therefore this section is sorting the data by dates and extract the features from the pandas datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d4dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = data.copy()\n",
    "\n",
    "data_features['gap'] = (data_features['out'] - data_features['out'].shift()).shift()\n",
    "data_features.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb413b2",
   "metadata": {},
   "source": [
    "Function to extract features from the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6071c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    out = df.copy()\n",
    "    out[\"hour\"] = out.index.hour\n",
    "    out[\"day\"] = out.index.day\n",
    "    out[\"month\"] = out.index.month\n",
    "    out[\"year\"] = out.index.year\n",
    "\n",
    "    out['quarter'] = out.index.quarter\n",
    "    out['dayofyear'] = out.index.dayofyear\n",
    "    out['dayofmonth'] = out.index.day    \n",
    "    out['weekofyear'] = out.index.isocalendar().week.astype(np.int64)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d961d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_features = get_features(data_features)\n",
    "\n",
    "data_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d67b9c",
   "metadata": {},
   "source": [
    "## Grouping N input points for the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a415d5a1",
   "metadata": {},
   "source": [
    "To guess the next point, the model required need the previous points. Therefore, this section is adding the data of the previous points into the row of each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce3905e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_colums_names(column_names, N):\n",
    "    column_names = list(column_names)\n",
    "    print(column_names)\n",
    "    names = []\n",
    "    for i in range(N, 0, -1):\n",
    "        for name in column_names:\n",
    "            names.append(name + str(i))\n",
    "    names.extend(column_names)\n",
    "    print(names)\n",
    "    return names\n",
    "\n",
    "data_features.reset_index(inplace=True)\n",
    "all_available_features = list(data_features.columns)\n",
    "\n",
    "N = 3 # Number of points to predict future\n",
    "data_multiple = data_features.copy()\n",
    "\n",
    "for i in range(1, N):\n",
    "    data_multiple = pd.concat([data_multiple.iloc[:-1].reset_index(drop=True), data_features.iloc[i:].reset_index(drop=True)], axis=1)\n",
    "\n",
    "data_multiple = pd.concat([data_multiple.iloc[:-1].reset_index(drop=True), data_features.iloc[N:].reset_index(drop=True)], axis=1)\n",
    "\n",
    "data_multiple.columns = get_colums_names(data_features.columns, N)\n",
    "data_multiple.set_index(\"date\", inplace=True)\n",
    "\n",
    "data_multiple.info()\n",
    "data_multiple\n",
    "\n",
    "dfi.export(data_multiple, \"Data multiple.png\", max_rows=6, max_cols=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a739f85",
   "metadata": {},
   "source": [
    "## Choosing the wanted features for training and target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f90bf",
   "metadata": {},
   "source": [
    "Define the training feature that must be used for the training. The code below allow to choose all the features of the previous points by creating a list of features name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212509a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = data_multiple.columns\n",
    "\n",
    "training_features_list = ['hour', 'day', 'month', 'year', 'quarter', 'dayofyear',\n",
    "       'dayofmonth', 'weekofyear', 'out']\n",
    "\n",
    "def is_training_feature(feature, training_features):\n",
    "    for training_feature in training_features:\n",
    "        if feature != \"out\" and \\\n",
    "        training_feature == feature[:len(training_feature)] and \\\n",
    "        (feature[len(training_feature):].isnumeric() or feature[len(training_feature):] == \"\"):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "training_features = list(filter(lambda x : is_training_feature(x, training_features_list), all_features))\n",
    "print(training_features)\n",
    "\n",
    "target = \"out\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fc0bca",
   "metadata": {},
   "source": [
    "## Creating train_test subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9bd42",
   "metadata": {},
   "source": [
    "To train and evaluate the performance of the model, two partition are created, one that is used for training the model and the other one to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data_multiple, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bfd59d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d2b06",
   "metadata": {},
   "source": [
    "## Visualizing the partition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa5114f",
   "metadata": {},
   "source": [
    "This section allow us to make sure the partitions are well made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd424ea1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(15, 15), sharex=True)\n",
    "\n",
    "train['out'].plot(ax=ax[0], title='Data Train/Test Split')\n",
    "test['out'].plot(ax=ax[0])\n",
    "ax[0].legend(['Training Set', 'Test Set'])\n",
    "\n",
    "train['out'].plot(ax=ax[1], title='Training Data')\n",
    "ax[1].legend(['Training Set'])\n",
    "\n",
    "test['out'].plot(ax=ax[2], title='Testing Data', color=\"orange\")\n",
    "ax[2].legend(['Test Set'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48fc4ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5), sharex=True)\n",
    "\n",
    "train['out'].plot(ax=ax, title='Data Train/Test Split')\n",
    "test['out'].plot(ax=ax)\n",
    "ax.legend(['Training Set', 'Test Set'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d022a45",
   "metadata": {},
   "source": [
    "## Training our model using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e0155",
   "metadata": {},
   "source": [
    "In this section we train the XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ffd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfe029a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "args = {\n",
    "    \"n_estimators\" : 1000,\n",
    "    \"learning_rate\" : 0.01,\n",
    "}\n",
    "\n",
    "# If you don't have a GPU card with the correspond driver you can uncomment the line below to use the CPU instead\n",
    "# reg = xgb.XGBRegressor(**args)\n",
    "reg = xgb.XGBRegressor(tree_method=\"gpu_hist\",\n",
    "                       **args)\n",
    "\n",
    "t = time()\n",
    "reg.fit(train[training_features], train[target],\n",
    "        eval_set=[(train[training_features], train[target]), (test[training_features],test[target])],\n",
    "        verbose=100)\n",
    "print(time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de338a80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396376e",
   "metadata": {},
   "source": [
    "## Predict and evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d3014",
   "metadata": {},
   "source": [
    "In this section the model is tested and evaluated by using the score function of XGBoost regressor. The score method of XGBoost use a RMSE metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf1259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = reg.predict(train[training_features])\n",
    "preds_test = reg.predict(test[training_features])\n",
    "\n",
    "print(\"Training ;\", reg.score(train[training_features], train[target]))\n",
    "print(\"Testing :\", reg.score(test[training_features], test[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e58e2c",
   "metadata": {},
   "source": [
    "Plotting the prediction on the train and test partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5907d107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6, 1, figsize=(15, 30), sharex=True)\n",
    "\n",
    "train['out'].plot(ax=ax[0], title='Training Data/predicted value', color='r', alpha=1)\n",
    "ax[0].plot(train.index, preds_train, color='b', alpha=0.5)\n",
    "ax[0].legend(['Training Set', 'Prediction'])\n",
    "\n",
    "train['out'].plot(ax=ax[1], title='Training Data')\n",
    "ax[1].legend(['Training Set'])\n",
    "\n",
    "ax[2].plot(train.index, preds_train, color=\"orange\")\n",
    "ax[2].legend(['Prediction'])\n",
    "\n",
    "test['out'].plot(ax=ax[3], title='Testing Data/predicted value', alpha=0.7)\n",
    "ax[3].plot(test.index, preds_test, alpha=0.7)\n",
    "ax[3].legend(['Testing Set', 'Prediction'])\n",
    "\n",
    "test['out'].plot(ax=ax[4], title='Testing Data')\n",
    "ax[4].legend(['Testing Set'])\n",
    "\n",
    "ax[5].set_title('Prediction value')\n",
    "ax[5].plot(test.index, preds_test, color=\"orange\")\n",
    "ax[5].legend(['Prediction'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfa48de",
   "metadata": {},
   "source": [
    "Plotting the prediction over one week on the testing partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f9248",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "period1 = '2018 05 01'\n",
    "period2 = '2018 05 07'\n",
    "\n",
    "preds_period = reg.predict(test.loc[period1:period2][training_features])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.set_title('Testing Data/predicted value')\n",
    "ax.plot(test.loc[period1:period2].index, preds_period, alpha=0.7, color=\"blue\")\n",
    "test.loc[period1:period2]['out'].plot(ax=ax, alpha=0.7, color=\"red\")\n",
    "ax.legend(['Prediction', 'Testing Set'])\n",
    "\n",
    "pltshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea53a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(data=reg.feature_importances_,\n",
    "             index=reg.get_booster().feature_names,\n",
    "             columns=['importance'])\n",
    "fi.sort_values('importance').plot(kind='barh', title='Feature Importance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf25272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "mapping_dict = {}\n",
    "for feature in all_available_features:\n",
    "    for i in range(N, 0, -1):\n",
    "        if (feature != \"date\" and feature != \"out\") or i != 1:\n",
    "            mapping_dict[feature + str(i)] = feature + str(i-1) if i > 1 else feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b1d103",
   "metadata": {},
   "source": [
    "## Predicting the future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b17c6da",
   "metadata": {},
   "source": [
    "In this section the future is predicted over multiple point by guessing one point and then using this new point to predict the next one and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955a753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "future_pred = [[], []]\n",
    "start_index = np.random.randint(0, len(test))\n",
    "nb_points = 50\n",
    "\n",
    "new_row = test.iloc[start_index:(start_index + 1), :].drop(columns=['out'])\n",
    "\n",
    "for _ in range(nb_points):\n",
    "    last_row = new_row.copy()\n",
    "    pred = reg.predict(new_row[training_features])[0]\n",
    "    future_pred[0].append(new_row.index)\n",
    "    future_pred[1].append(pred)\n",
    "\n",
    "\n",
    "    for k in mapping_dict:\n",
    "        new_row[k] = last_row[mapping_dict[k]]\n",
    "    new_row[\"date1\"] = last_row.index\n",
    "    new_row.index += pd.Timedelta('1h')\n",
    "    new_row = get_features(new_row)\n",
    "    new_row['out1'] = pred\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.set_title('Testing Data/predicted value based on old prediction')\n",
    "ax.plot(test.iloc[start_index:(start_index + nb_points)]['out'], alpha=1, color=\"blue\")\n",
    "ax.plot(future_pred[0], future_pred[1], alpha=0.7, color=\"red\")\n",
    "ax.legend(['Testing Set', 'Prediction'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bbfef8",
   "metadata": {},
   "source": [
    "The same code as above but to plot multiple try at different index of the testing dataset at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e91310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_tot_try = 4\n",
    "\n",
    "fig, ax = plt.subplots(nb_tot_try, 1, figsize=(15, 5 * nb_tot_try))\n",
    "\n",
    "for nb_try in range(nb_tot_try):\n",
    "    future_pred = [[], []]\n",
    "    start_index = np.random.randint(0, len(test))\n",
    "    nb_points = 200\n",
    "\n",
    "    new_row = test.iloc[start_index:(start_index + 1), :].drop(columns=['out'])\n",
    "\n",
    "    for _ in range(nb_points):\n",
    "        last_row = new_row.copy()\n",
    "        pred = reg.predict(new_row[training_features])[0]\n",
    "        future_pred[0].append(new_row.index)\n",
    "        future_pred[1].append(pred)\n",
    "\n",
    "\n",
    "        for k in mapping_dict:\n",
    "            new_row[k] = last_row[mapping_dict[k]]\n",
    "        new_row[\"date1\"] = last_row.index\n",
    "        new_row.index += pd.Timedelta('1h')\n",
    "        new_row = get_features(new_row)\n",
    "        new_row['out1'] = pred\n",
    "\n",
    "\n",
    "    ax[nb_try].set_title('Testing Data/predicted value based on old prediction')\n",
    "    ax[nb_try].plot(test.iloc[start_index:(start_index + nb_points)]['out'], alpha=1, color=\"blue\")\n",
    "    ax[nb_try].plot(future_pred[0], future_pred[1], alpha=0.7, color=\"red\")\n",
    "    ax[nb_try].legend(['Prediction', 'Testing Set'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7210f",
   "metadata": {},
   "source": [
    "The results are inconsistent, sometime the prediction is really good for close time prediction and some time the prediction is getting wrong pretty fast."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.844px",
    "left": "590px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
